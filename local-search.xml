<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>DnCNN</title>
    <link href="/2024/01/27/%E7%AC%AC%E4%B8%80%E7%AF%87/"/>
    <url>/2024/01/27/%E7%AC%AC%E4%B8%80%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<p>一、摘要<br>本文通过研究构建前馈去噪卷积神经网络（DnCNNs），将深度架构、学习算法和正则化方法应用到图像去噪中。具体而言，作者利用残差学习和批量标准化加速了训练过程，并提高了去噪性能。与现有的针对特定信噪比下的加性高斯噪声（AWGN）训练特定模型的判别式去噪模型不同，作者的DnCNN模型能够处理未知信噪比下的高斯去噪（即盲目高斯去噪）。通过残差学习策略，DnCNN在隐藏层中隐式地去除了潜在的清晰图像。这个特性启发作者训练一个DnCNN模型来解决多个通用图像去噪任务，如高斯去噪、单幅图像超分辨率和JPEG图像去块。大量实验证明，作者的DnCNN模型不仅在几个通用图像去噪任务中表现出高效性，而且通过GPU计算可以高效实现。</p><p>二、比较<br>图像去噪是低级别视觉（与基本视觉处理和感知相关的任务，涉及对原始图像的低级特征进行提取和分析，如边缘检测、角点检测、颜色分割、图像增强、图像去噪等）中经典的研究领域，有许多实际应用。而图像先验建模在图像去噪中起着核心作用，在过去的几十年中，已经开发了各种模型来建模图像先验。但大多数方法通常存在两个主要缺点。首先，这些方法在测试阶段通常涉及复杂的优化问题，很难在不牺牲计算效率的情况下达到高性能，十分耗时。其次，这些模型一般是非凸的（在优化问题中，凸优化是指目标函数为凸函数，约束条件为线性约束的一类特殊问题。凸优化问题具有很好的性质，可以通过有效的算法找到全局最优解。而非凸优化问题则更加复杂，往往存在多个局部最优解，且难以确定全局最优解。在机器学习中，神经网络的损失函数通常是非凸的，因此需要使用迭代算法来寻找局部最优解），并涉及到几个手动选择的参数，提供了一定的余地来提高去噪性能。<br>为了克服基于先验方法的局限性，在截断推理过程的背景下，近年来已经发展出了几种判别学习方法来学习图像先验模型，如梯度缩减场（CSF）方法和非线性反应扩散（TNRD）模型。CSF和TNRD采用的先验是基于分析模型的，该模型在捕捉图像结构的全部特征方面存在限制。此外，参数是通过阶段性贪婪训练加上所有阶段的联合微调来学习的，并涉及许多手动设计的参数。最后，它们只是为特定的噪声水平训练了特定的模型，在盲目图像去噪方面存在局限性。<br>作者不是使用显式图像先验来学习判别模型，而是将图像去噪视为一个简单的判别学习问题，通过前馈卷积神经网络（CNN）从噪声图像中分离出噪声。DnCNN有诸多优点。首先，具有非常深的架构的CNN能够有效增加利用图像特征的容量和灵活性。其次，作者采用修正线性单元（ReLU），批归一化和残差学习加速训练过程并改善去噪性能。另外，DnCNN非常适合在现代强大的GPU上进行运算，提高了运行性能。经过对比发现，对于未知噪声水平的高斯去噪（即盲目高斯去噪），DnCNN只需一个模型仍然能够胜过针对特定噪声水平训练的BM3D 和TNRD。<br>与直接输出去噪图像x̂不同，DnCNN被设计为预测残差图像v̂，即噪声观察和潜在干净图像之间的差异。换句话说，DnCNN通过隐藏层中的操作隐式地去除了潜在的干净图像。DnCNN还可以扩展处理几个一般的图像去噪任务，包括高斯去噪、SISR（对单个低分辨率图像进行处理，从而获得高分辨率的图像的技术）和JPEG图像去块效应（去除对JPEG图像进行高度压缩时，引入的一种视觉上不愉快的现象——“块效应”）。</p><p>三、收获<br>1.Conv是深度学习中常用的缩写，它指的是卷积操作（Convolution）。卷积操作是一种在神经网络中广泛应用的操作，用于提取输入数据中的特征。<br>卷积操作主要用于处理具有空间结构的数据，例如图像或文本。它通过将一个滤波器（也称为卷积核：某个点与周围点加权平均的权值，描述周围点所占的权重）从输入数据上滑动，并计算滤波器与输入数据之间的加权求和来生成输出。滤波器的参数可以通过训练来学习，使得网络能够自动学习到不同类型的特征。在图像处理中，卷积操作可以用于提取图像的边缘、纹理、形状等特征。<br>卷积操作具有以下特点：<br>局部连接性：每个神经元只与输入数据的一个小区域相连，这样可以减少参数量和计算复杂度。<br>参数共享：在卷积操作中，滤波器的参数在整个输入数据上是共享的，这可以大幅减少参数数量，提高模型的效率。<br>平移不变性：无论输入数据中的特征出现在哪个位置，卷积操作都能够检测到它们，这使得卷积操作具有平移不变性的特性。<br>在神经网络中，卷积操作通常与激活函数（如ReLU）和其他层（如池化层）一起使用，以构建更深层次的模型。</p><p>2.高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。噪声水平（Noise Level）是指图像中存在的噪声的强度或程度。在数字图像中，噪声是由各种因素引起的随机、不希望的信号干扰，它可以降低图像的质量和清晰度。</p><p>噪声水平通常用于描述图像中噪声的相对强度或能量。一般来说，较高的噪声水平表示图像中噪声成分更多，而较低的噪声水平表示图像中噪声成分较少。</p><p>3.Residual Learning（残差学习）：CNN的残差学习最初提出是为了解决性能退化问题，即随着网络深度增加，即使训练准确度也开始降低，导致模型无法有效地学习更深层次的特征。残差学习通过引入“残差块”（residual blocks），允许网络直接学习输入和输出之间的残差，残差网络明确地为几个堆叠的层学习残差映射。通过这种残差学习策略，可以轻松训练极深的CNN，解决深度神经网络训练中的梯度消失和梯度爆炸问题，提高模型的学习能力和性能。</p><p>4.ResNet（残差网络）是一种深度残差学习框架，基本构建块是残差块（residual block），每个残差块包含两个或三个卷积层，并在其中间添加了残差连接（residual connection），残差连接通过添加跨层的直接连接来绕过网络层之间的非线性变换，将输入的信号与输出的信号相加。这样，网络可以更容易地学习到残差部分，即恒等映射（identity mapping），从而避免了梯度消失和模型退化问题。</p><p>5.梯度消失是指在深度神经网络中，反向传播算法中的梯度逐渐变小并趋近于零的现象。在训练过程中，梯度用于更新神经网络参数，以最小化损失函数。然而，当梯度值接近于零时，网络的权重更新几乎不会发生，导致网络无法有效学习和调整。</p><p>6.Batch Normalization（批标准化）是一种常用的深度神经网络技术，旨在加快训练速度并提高模型性能。它通过在神经网络的隐藏层中对每个小批量数据进行标准化处理来解决梯度消失和梯度爆炸问题。<br>在传统的神经网络中，输入数据经过多个层级的变换后，每一层的输入分布可能会发生变化，导致训练过程中的内部协变量偏移（internal covariate shift）。这种偏移会使每一层的参数需要频繁地进行调整，从而增加了训练的难度。<br>批量标准化通过将每一层的输入进行标准化，即使得其均值接近于0，方差接近于1，从而将输入数据的分布稳定在一个较小的范围内。<br>具体来说，批量标准化的操作包括两个主要步骤：计算每个小批量数据的均值和方差，并对数据进行标准化。然后，通过调整两个可学习的参数（缩放因子和偏移量），将标准化后的数据重新映射到所需的范围。</p><p>7.Zero padding（零填充）是一种在卷积操作中常用的技术，用于在输入数据周围添加零值来扩展其尺寸。具体而言，对于二维输入数据（如图像），零填充会在图像的边缘周围添加额外的行和列，并将其设置为零值。<br>主要目的是应对卷积操作中的边界效应问题。在进行卷积操作时，卷积核通常只能访问到输入数据中的一部分，而位于输入边缘的像素则会被相邻像素覆盖得较少。这导致输出的尺寸相对减小，并且边缘像素的信息损失较多。<br>通过对输入数据进行零填充，可以保持输出的尺寸与输入相同，并且确保了边缘像素也能够得到充分的考虑。零填充还有助于保持输入数据的空间结构，减少因边界像素丢失而引起的信息损失。<br>例如，对于一个3x3的输入图像，如果使用1个单位的零填充，则在图像的四周各添加1行和1列的零像素。这样，在进行卷积操作时，卷积核就可以完整地访问到原始图像的所有像素。<br>零填充在卷积神经网络（CNN）中被广泛使用，特别是在处理图像时。它不仅可以解决边界效应问题，还有助于提取更丰富的特征，并保持输入输出尺寸的一致性。</p><p>8.激活函数（Activation Function）是神经网络中的一种非线性函数，它将输入信号映射到输出信号，并引入了非线性变换，使得神经网络能够学习和表示更复杂的模式和特征。<br>在神经网络的每个神经元中，激活函数对输入进行处理，并生成输出信号。激活函数通常被应用于神经网络的隐藏层和输出层，而输入层通常不需要使用激活函数。</p><p>9.ReLU（Rectified Linear Unit，修正线性单元）是一种激活函数，在深度学习中经常被用作神经网络的非线性变换函数。<br>ReLU函数定义如下：<br>f(x) &#x3D; max(0, x),简单来说，对于负数输入，ReLU函数输出为0，而对于非负数输入，输出等于输入本身。<br>ReLU函数的优点有以下几个方面：<br>非线性：具有非线性的特性，使神经网络能够学习到更复杂的模式和特征。<br>计算高效：计算简单，只需要比较输入与零的大小并输出较大的值，因此计算速度快。<br>防止梯度消失：缓解梯度消失问题，有助于训练深层神经网络。</p><p>10.图像先验是指对图像的先验知识或假设，它描述了图像在真实世界中的特性和统计规律。图像先验是基于大量观察和经验得出的，可以用来约束图像去噪、恢复、分割等任务，不同的图像先验模型可以用来捕捉图像的不同属性和结构。</p><p>11.判别模型学习（Discriminative model learning）是指在机器学习中，通过对已知输入和对应的输出数据进行学习，建立一个模型来预测未知输入对应的输出。我们的目标是寻找一个函数或模型，该函数能够将输入数据映射到正确的输出类别或值。常见的判别学习任务包括二分类（垃圾邮件分类、疾病诊断）、多分类（手写数字识别、图像分类）和回归问题（房价预测、股票价格预测）。</p><p>12.阶段性贪婪训练（Greedy Layer-wise Training）是一种用于训练深度神经网络（DNN）的策略，基本思想是将整个深度神经网络分解为多个较浅的子网络，然后通过逐层训练每个子网络来逐步构建整个网络。具体地，该方法首先将输入数据传递到第一个隐藏层，并仅训练第一个隐藏层的参数。一旦第一个隐藏层达到了满意的性能水平，就将其冻结，并添加第二个隐藏层。然后，使用已训练好的第一个隐藏层参数作为固定输入，对第二个隐藏层进行训练。重复这个过程，直到所有隐藏层都被逐步添加和训练。最后，在整个网络中进行端到端的微调，以进一步提高性能。<br>优点：可以有效地解决深度神经网络训练中的梯度消失和梯度爆炸问题。此外，它还可以加速训练过程，并使得神经网络更容易收敛到较好的局部最优解。<br>缺点：首先，逐层训练可能导致每个子网络的参数在全局网络中不是最佳的配置。其次，由于每个子网络都是独立训练的，因此无法充分利用整个数据集的信息。最后，该方法可能需要更多的计算资源和时间来完成整个训练过程。</p><p>13.网络深度（Network Depth）是指神经网络中的层数，即网络中包含的隐藏层的数量。深度学习模型的深度是指其具有多少层。增加网络的深度是提高深度学习模型表示能力的一种方法。随着网络深度的增加，模型可以学习更复杂、更抽象的特征表达，从而提高其在各种任务中的性能。较浅的网络可能只能捕捉到低级别的特征。当然，增加网络深度也会带来挑战。例如，梯度消失和梯度爆炸问题都可能会影响网络的训练。</p><p>四、实验<br>去噪神经网络的感受野（在卷积神经网络中，每个神经元的感受野由其所在层的滤波器大小和步幅决定。当经过多个卷积层和池化层时，感受野会逐渐增大，从而能够捕捉更广阔的空间信息。具体来说，对于卷积层而言，每个神经元的感受野大小与其所在的卷积核大小有关。如果卷积核大小为3x3，则该神经元的感受野为3x3。通过堆叠多个卷积层，感受野可以得到扩大）大小与去噪方法的有效块（在特征提取过程中，图像被分成不同的块，然后从每个块中提取出特征。在这种情况下，有效块是指被视为具有可靠和相关信息的图像块）大小相关。对于具有一定噪声水平的高斯去噪，将DnCNN 的感受野大小设置为 35×35，对应的深度为 17，对于其他一般图像去噪任务，采用更大的感受野并将深度设置为 20。</p><p>在训练阶段，使用来自各种噪声水平（例如，σ∈[0, 55]）的噪声图像来训练单个 DnCNN 模型。然后通过为几个通用图像去噪任务学习单个模型来进一步扩展DnCNN，即盲高斯去噪、SISR 和 JPEG 去块。在训练阶段，利用来自各种噪声水平的 AWGN 图像、具有多个放大因子的下采样图像和具有不同质量因子的 JPEG 图像来训练单个 DnCNN 模型。</p><p><img src="/20200511085821759-1.png" alt="Alt text"></p>]]></content>
    
    
    
    <tags>
      
      <tag>阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/01/23/hello-world/"/>
    <url>/2024/01/23/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
